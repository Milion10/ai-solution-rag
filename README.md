# AI Solution - IA Conversationnelle On-Premise

Solution IA conversationnelle privÃ©e pour PME tech avec RAG (Retrieval-Augmented Generation).

## ğŸš€ Quick Start

**PrÃ©-requis:**
- Docker Desktop 24+ installÃ©
- 16GB RAM minimum
- Python 3.11+ (pour dÃ©veloppement backend)
- Node.js 20+ (pour dÃ©veloppement frontend)

**DÃ©marrage rapide:**
```bash
cd docker
docker-compose up -d
```

- Frontend: http://localhost:3000
- Backend API: http://localhost:8000
- API Docs: http://localhost:8000/docs

## ğŸ“ Structure Projet

```
ai-solution/
â”œâ”€â”€ frontend/           # Next.js App Router
â”œâ”€â”€ backend/            # FastAPI + RAG
â”œâ”€â”€ docker/             # Docker Compose + Dockerfiles
â”œâ”€â”€ docs/               # Documentation
â””â”€â”€ scripts/            # Scripts utilitaires
```

## ğŸ“ Phase Actuelle: POC (Proof of Concept)

Objectif: Valider stack technique avec chat fonctionnel + RAG sur 1 PDF.

**FonctionnalitÃ©s POC:**
- âœ… Chat conversationnel basique
- âœ… Upload 1 PDF
- âœ… RAG pipeline (chunking, embeddings, recherche)
- âœ… LLM local (Mistral 7B ou Llama 3.1 8B GGUF Q4)
- âœ… Interface type ChatGPT

**Hors scope POC:**
- Auth JWT (Phase 1)
- Multi-documents (Phase 1)
- Profils utilisateurs (Phase 1)
- Citations avancÃ©es (Phase 1)

## ğŸ“š Documentation

Voir `docs/` pour guides dÃ©taillÃ©s:
- Installation complÃ¨te
- Architecture technique
- Guides dÃ©veloppement
- API Reference

## ğŸ› ï¸ Tech Stack

- **Frontend**: Next.js 14 + Tailwind + shadcn/ui
- **Backend**: FastAPI + Python 3.11
- **IA**: LangChain + Mistral/Llama (GGUF) + sentence-transformers
- **Base donnÃ©es**: PostgreSQL 16 + pgvector
- **Stockage**: MinIO (S3-compatible)
- **Cache**: Redis

## ğŸ“ License

PropriÃ©taire - Tous droits rÃ©servÃ©s
