"""
Module de g√©n√©ration d'embeddings vectoriels
Utilise sentence-transformers pour convertir du texte en vecteurs
"""
from sentence_transformers import SentenceTransformer
from typing import List, Union
import numpy as np
import logging
import os

logger = logging.getLogger(__name__)


class EmbeddingsGenerator:
    """
    G√©n√®re des embeddings vectoriels √† partir de texte
    """
    
    def __init__(self, model_name: str = "all-MiniLM-L6-v2"):
        """
        Initialise le g√©n√©rateur d'embeddings
        
        Args:
            model_name: Nom du mod√®le sentence-transformers
                - all-MiniLM-L6-v2: 384 dims, l√©ger, rapide (recommand√©)
                - paraphrase-multilingual-MiniLM-L12-v2: 384 dims, multilingue
                - all-mpnet-base-v2: 768 dims, plus pr√©cis mais plus lourd
        """
        self.model_name = model_name
        
        logger.info(f"Chargement du mod√®le d'embeddings: {model_name}")
        
        try:
            self.model = SentenceTransformer(model_name)
            self.embedding_dim = self.model.get_sentence_embedding_dimension()
            
            logger.info(f"‚úÖ Mod√®le charg√©: {model_name} ({self.embedding_dim} dimensions)")
        
        except Exception as e:
            logger.error(f"‚ùå Erreur chargement mod√®le: {e}")
            raise
    
    
    def generate_embedding(self, text: str) -> np.ndarray:
        """
        G√©n√®re un embedding pour un texte
        
        Args:
            text: Texte √† transformer en vecteur
        
        Returns:
            Vecteur numpy de dimension self.embedding_dim
        """
        if not text or not text.strip():
            logger.warning("Texte vide fourni pour embedding")
            return np.zeros(self.embedding_dim)
        
        # G√©n√©rer embedding
        embedding = self.model.encode(text, convert_to_numpy=True)
        
        return embedding
    
    
    def generate_embeddings(self, texts: List[str], batch_size: int = 32) -> np.ndarray:
        """
        G√©n√®re des embeddings pour une liste de textes (plus rapide en batch)
        
        Args:
            texts: Liste de textes
            batch_size: Taille des batchs pour l'encodage
        
        Returns:
            Array numpy de shape (len(texts), embedding_dim)
        """
        if not texts:
            logger.warning("Liste de textes vide")
            return np.array([])
        
        logger.info(f"G√©n√©ration embeddings pour {len(texts)} textes...")
        
        # G√©n√©rer embeddings en batch
        embeddings = self.model.encode(
            texts,
            batch_size=batch_size,
            show_progress_bar=len(texts) > 100,  # Afficher barre de progression si > 100 textes
            convert_to_numpy=True
        )
        
        logger.info(f"‚úÖ {len(embeddings)} embeddings g√©n√©r√©s")
        
        return embeddings
    
    
    def compute_similarity(self, embedding1: np.ndarray, embedding2: np.ndarray) -> float:
        """
        Calcule la similarit√© cosine entre deux embeddings
        
        Args:
            embedding1: Premier vecteur
            embedding2: Deuxi√®me vecteur
        
        Returns:
            Score de similarit√© entre 0 et 1
        """
        from numpy.linalg import norm
        
        # Similarit√© cosine
        similarity = np.dot(embedding1, embedding2) / (norm(embedding1) * norm(embedding2))
        
        return float(similarity)


# Instance globale (singleton)
_embeddings_instance = None

def get_embeddings_generator() -> EmbeddingsGenerator:
    """Retourne l'instance singleton du g√©n√©rateur d'embeddings"""
    global _embeddings_instance
    if _embeddings_instance is None:
        # Utiliser config centralis√©e
        try:
            from config import settings
            model_name = settings.embeddings_model
        except ImportError:
            # Fallback pour tests isol√©s
            model_name = os.getenv("EMBEDDINGS_MODEL", "all-MiniLM-L6-v2")
        
        _embeddings_instance = EmbeddingsGenerator(model_name)
    return _embeddings_instance


if __name__ == "__main__":
    # Test du g√©n√©rateur d'embeddings
    generator = EmbeddingsGenerator()
    
    print(f"\nü§ñ Mod√®le: {generator.model_name}")
    print(f"üìê Dimensions: {generator.embedding_dim}\n")
    
    # Test avec quelques phrases
    texts = [
        "L'intelligence artificielle transforme le monde",
        "AI is transforming the world",
        "Le chat dort sur le canap√©"
    ]
    
    embeddings = generator.generate_embeddings(texts)
    
    print(f"‚úÖ G√©n√©r√© {len(embeddings)} embeddings\n")
    
    # Calcul similarit√©s
    print("Similarit√©s:")
    for i in range(len(texts)):
        for j in range(i+1, len(texts)):
            sim = generator.compute_similarity(embeddings[i], embeddings[j])
            print(f"  '{texts[i][:30]}...' vs '{texts[j][:30]}...': {sim:.3f}")
