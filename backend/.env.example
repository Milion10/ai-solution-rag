# Backend Environment Variables
# Copier vers .env et modifier les valeurs

# ===========================================
# DATABASE
# ===========================================
DATABASE_URL=postgresql://ai_user:change-me-in-production@localhost:5432/ai_solution

# ===========================================
# REDIS
# ===========================================
REDIS_URL=redis://localhost:6379

# ===========================================
# MINIO (Stockage fichiers)
# ===========================================
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
MINIO_BUCKET_NAME=ai-documents

# ===========================================
# SECURITY
# ===========================================
# ⚠️ GÉNÉRER UN SECRET FORT EN PRODUCTION !
# Commande: python -c 'import secrets; print(secrets.token_urlsafe(32))'
JWT_SECRET=your-secret-key-change-in-production
JWT_ALGORITHM=HS256
JWT_EXPIRATION_HOURS=24

# ===========================================
# AI / LLM
# ===========================================
# Provider: "ollama" (local) ou "groq" (cloud)
LLM_PROVIDER=ollama

# Ollama Configuration (local)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=mistral:7b-instruct

# Groq Configuration (cloud, pour développement rapide)
# Obtenir une clé sur: https://console.groq.com
GROQ_API_KEY=
GROQ_MODEL=llama-3.3-70b-versatile

# Embeddings
EMBEDDINGS_MODEL=all-MiniLM-L6-v2

# Legacy (non utilisé)
LLM_MODEL_PATH=models/mistral-7b-instruct-v0.2.Q4_K_M.gguf

# ===========================================
# SERVER
# ===========================================
HOST=0.0.0.0
PORT=8000
DEBUG=true

# ===========================================
# RAG PARAMETERS
# ===========================================
CHUNK_SIZE=800
CHUNK_OVERLAP=200
TOP_K_RESULTS=5
SIMILARITY_THRESHOLD=0.7

# ===========================================
# LOGGING
# ===========================================
# Niveaux: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO
